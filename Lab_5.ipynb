{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DbJrUpARWhAd",
        "MI18l-l9WhAk",
        "1wrEGqBSWhAr",
        "gStgBJy2WhAx"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHX9p5jfTySS"
      },
      "source": [
        "## Задание 5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EnHNZtbXlH0"
      },
      "source": [
        "Набор данных тут: https://github.com/sismetanin/rureviews, также есть в папке [Data](https://drive.google.com/drive/folders/1YAMe7MiTxA-RSSd8Ex2p-L0Dspe6Gs4L). Те, кто предпочитает работать с английским языком, могут использовать набор данных `sms_spam`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJox-LoonoPx"
      },
      "source": [
        "Применим полученные навыки и решим задачу анализа тональности отзывов. \n",
        "\n",
        "Нужно повторить весь пайплайн от сырых текстов до получения обученной модели.\n",
        "\n",
        "Обязательные шаги предобработки:\n",
        "1. токенизация\n",
        "2. приведение к нижнему регистру\n",
        "3. удаление стоп-слов\n",
        "4. лемматизация\n",
        "5. векторизация (с настройкой гиперпараметров)\n",
        "6. построение модели\n",
        "7. оценка качества модели\n",
        "\n",
        "Обязательно использование векторайзеров:\n",
        "1. мешок n-грамм (диапазон для n подбирайте самостоятельно, запрещено использовать только униграммы).\n",
        "2. tf-idf ((диапазон для n подбирайте самостоятельно, также нужно подбирать гиперпараметры max_df, min_df, max_features)\n",
        "3. символьные n-граммы (диапазон для n подбирайте самостоятельно)\n",
        "\n",
        "В качестве классификатора нужно использовать наивный байесовский классификатор. \n",
        "\n",
        "Для сравнения векторайзеров между собой используйте precision, recall, f1-score и accuracy. Для этого сформируйте датафрейм, в котором в строках будут разные векторайзеры, а в столбцах разные метрики качества, а в  ячейках будут значения этих метрик для соответсвующих векторайзеров."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "U3OkM3OIZDrJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/evlko/CS-493/main/Data/sms_spam.csv')\n",
        "\n",
        "df['type'] = df['type'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "y = df['type']\n",
        "X = df.drop(columns=['type'])"
      ],
      "metadata": {
        "id": "rx7-Gg2JY-5K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Предобработка"
      ],
      "metadata": {
        "id": "V3XbekxiniaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)"
      ],
      "metadata": {
        "id": "vLuDJQ0B3qRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(text):\n",
        "    \"\"\"Функция предобработки текста.\n",
        "    Убираем всю пунктуацию;\n",
        "    Приводим текст к нижнему регистру;\n",
        "    Циклом проходимся по токенам и проверяем, есть ли их лемма в стоп-словах, если нет, то сохраняем лемму токена.\n",
        "    \"\"\"\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    text = [lemmatizer.lemmatize(word) for word in word_tokenize(text) if lemmatizer.lemmatize(word) not in stopwords] \n",
        "    text = ' '.join(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "X['text'] = X['text'].apply(preprocess)"
      ],
      "metadata": {
        "id": "Ika_ZcSXXlXr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Построение модели"
      ],
      "metadata": {
        "id": "hW1crlMCgaSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB \n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk import ngrams\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "TagrHT_bpRlw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
        "\n",
        "# dataframe для сравнения векторайзеров\n",
        "df_scores = pd.DataFrame(columns=['vectorizer', 'precision', 'recall', 'f1-score','accuracy'])"
      ],
      "metadata": {
        "id": "wH_vgi9slOzT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### мешок n-грамм"
      ],
      "metadata": {
        "id": "2cx8leYRlMLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_name = 'bag of word n-grams'"
      ],
      "metadata": {
        "id": "V5bQktEMGtYx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаем экземпляр pipeline - последовательность шагов предобработки и модель\n",
        "pipeline = Pipeline([\n",
        "           ('ngram', CountVectorizer()),\n",
        "           ('clf', MultinomialNB()),\n",
        "])\n",
        "\n",
        "# константы данного классификатора, будут использоваться для настройки параметров GridSearchCV\n",
        "MIN_NGRAM = 1\n",
        "MAX_NGRAM = 10\n",
        "\n",
        "n_grams = [(i, j) for i in range(MIN_NGRAM, MAX_NGRAM + 1) for j in range(MIN_NGRAM + 1, MAX_NGRAM + 1)]\n",
        "\n",
        "# создаем словарь параметров\n",
        "parameters = {\n",
        "    'ngram__ngram_range': n_grams,\n",
        "}\n",
        "\n",
        "# создаем экземпляр сетки поиска наилучших гиперпараметров\n",
        "grid_search = GridSearchCV(pipeline, parameters, cv=2, verbose=1, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train['text'], y_train)"
      ],
      "metadata": {
        "id": "AMwWXWD1JYAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Лучший диапазон n-gram слов: {grid_search.best_params_['ngram__ngram_range']}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7bJDQKsKfJd",
        "outputId": "256e3f44-d94e-4edd-acc5-623759c36f97"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучший диапазон n-gram слов: (1, 2).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = grid_search.predict(X_test['text'])\n",
        "\n",
        "# в метриках берем средневзвешенное, так как есть имбаланс классов\n",
        "precision, recall, f1score, support = precision_recall_fscore_support(y_test, predictions, average='weighted')\n",
        "acc = accuracy_score(y_test, predictions)\n",
        "scores = [vectorizer_name, precision, recall, f1score, acc]\n",
        "\n",
        "df_scores.loc[len(df_scores)] = scores"
      ],
      "metadata": {
        "id": "DXmq4P_vgc6q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### tf-idf"
      ],
      "metadata": {
        "id": "9pgU82bFlSSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_name = 'tf-idf'"
      ],
      "metadata": {
        "id": "i3GRW3aEIRTw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "           ('tfidf', TfidfVectorizer()),\n",
        "           ('clf', MultinomialNB()),\n",
        "])\n",
        "\n",
        "MIN_NGRAM = 1\n",
        "MAX_NGRAM = 6\n",
        "\n",
        "n_grams = [(i, j) for i in range(MIN_NGRAM, MAX_NGRAM + 1) for j in range(MIN_NGRAM, MAX_NGRAM + 1)]\n",
        "\n",
        "MIN_MIN_DF = 0\n",
        "MAX_MIN_DF = 0.01\n",
        "STEP_MIN_DF = 0.005\n",
        "\n",
        "MIN_MAX_DF = 0.5\n",
        "MAX_MAX_DF = 1.0\n",
        "STEP_MAX_DF = 0.25\n",
        "\n",
        "MIN_MAX_FEATURES = 5000\n",
        "MAX_MAX_FEATURES = 10000\n",
        "STEP_MAX_FEATURES = 1000\n",
        "\n",
        "parameters = {\n",
        "    'tfidf__ngram_range': n_grams,\n",
        "    'tfidf__min_df': np.arange(MIN_MIN_DF, MAX_MIN_DF + STEP_MIN_DF, STEP_MIN_DF),\n",
        "    'tfidf__max_df': np.arange(MIN_MAX_DF, MAX_MAX_DF + STEP_MAX_DF, STEP_MAX_DF),\n",
        "    'tfidf__smooth_idf': [True],\n",
        "    'tfidf__max_features': np.arange(MIN_MAX_FEATURES, MAX_MAX_FEATURES + STEP_MAX_FEATURES, STEP_MAX_FEATURES),\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, parameters, cv=2, verbose=1, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train['text'], y_train)"
      ],
      "metadata": {
        "id": "gnU9U8ztTWBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Лучшие параметы:\\nдиапазон n-gram слов: {grid_search.best_params_['tfidf__ngram_range']},\\nmin df: {grid_search.best_params_['tfidf__min_df']},\\nmax df: {grid_search.best_params_['tfidf__max_df']}\\nmax features: {grid_search.best_params_['tfidf__max_features']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew4zo2qnk6Wk",
        "outputId": "e2df94da-7921-4527-a763-42e793faee97"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметы:\n",
            "диапазон n-gram слов: (1, 2),\n",
            "min df: 0.005,\n",
            "max df: 0.5\n",
            "max features: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = grid_search.predict(X_test['text'])\n",
        "\n",
        "precision, recall, f1score, support = precision_recall_fscore_support(y_test, predictions, average='weighted')\n",
        "acc = accuracy_score(y_test, predictions)\n",
        "scores = [vectorizer_name, precision, recall, f1score, acc]\n",
        "\n",
        "df_scores.loc[len(df_scores)] = scores"
      ],
      "metadata": {
        "id": "zxw7Dan4lVXm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### символьные n-граммы"
      ],
      "metadata": {
        "id": "O8JULYl6m8br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_name = 'bag of char n-grams'"
      ],
      "metadata": {
        "id": "7HviOu9jITDL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "           ('ngram', CountVectorizer()),\n",
        "           ('clf', MultinomialNB()),\n",
        "])\n",
        "\n",
        "MIN_NGRAM = 1\n",
        "MAX_NGRAM = 6\n",
        "\n",
        "n_grams = [(i, j) for i in range(MIN_NGRAM, MAX_NGRAM + 1) for j in range(MIN_NGRAM, MAX_NGRAM + 1)]\n",
        "\n",
        "parameters = {\n",
        "    'ngram__ngram_range': n_grams,\n",
        "    'ngram__analyzer': ['char'],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, parameters, cv=2, verbose=1, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train['text'], y_train)"
      ],
      "metadata": {
        "id": "5b5p1WH5YMUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Лучший диапазон n-gram символов: {grid_search.best_params_['ngram__ngram_range']}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqzwLUwcYmqe",
        "outputId": "d70d8af5-ca85-4a5b-b2ae-fc177f2d5a27"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучший диапазон n-gram символов: (3, 3).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = grid_search.predict(X_test['text'])\n",
        "\n",
        "precision, recall, f1score, support = precision_recall_fscore_support(y_test, predictions, average='weighted')\n",
        "acc = accuracy_score(y_test, predictions)\n",
        "scores = [vectorizer_name, precision, recall, f1score, acc]\n",
        "\n",
        "df_scores.loc[len(df_scores)] = scores"
      ],
      "metadata": {
        "id": "HKXDHc_km-60"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### scores"
      ],
      "metadata": {
        "id": "lLrFP6Rf_u8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "2SkaTEBA_wOY",
        "outputId": "c3e5becb-fdf1-4053-94ed-1ded5c6f74d1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            vectorizer  precision    recall  f1-score  accuracy\n",
              "0  bag of word n-grams   0.983622  0.983813  0.983617  0.983813\n",
              "1               tf-idf   0.966832  0.967626  0.966574  0.967626\n",
              "2  bag of char n-grams   0.981456  0.981415  0.981435  0.981415"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29224c24-d7c8-4f3a-81a9-796fc8d368b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vectorizer</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bag of word n-grams</td>\n",
              "      <td>0.983622</td>\n",
              "      <td>0.983813</td>\n",
              "      <td>0.983617</td>\n",
              "      <td>0.983813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tf-idf</td>\n",
              "      <td>0.966832</td>\n",
              "      <td>0.967626</td>\n",
              "      <td>0.966574</td>\n",
              "      <td>0.967626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bag of char n-grams</td>\n",
              "      <td>0.981456</td>\n",
              "      <td>0.981415</td>\n",
              "      <td>0.981435</td>\n",
              "      <td>0.981415</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29224c24-d7c8-4f3a-81a9-796fc8d368b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29224c24-d7c8-4f3a-81a9-796fc8d368b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29224c24-d7c8-4f3a-81a9-796fc8d368b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QYTwyMtWhAZ"
      },
      "source": [
        "## Задание 5.2 Регулярные выражения\n",
        "\n",
        "Регулярные выражения - способ поиска и анализа строк. Например, можно понять, какие даты в наборе строк представлены в формате DD/MM/YYYY, а какие - в других форматах. \n",
        "\n",
        "Или бывает, например, что перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
        "\n",
        "Навык полезный, давайте в нём тоже потренируемся.\n",
        "\n",
        "Для работы с регулярными выражениями есть библиотека **re**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaUW5S4gWhAb"
      },
      "source": [
        "import re"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6aYh7Osl8xr"
      },
      "source": [
        "В регулярных выражениях, кроме привычных символов-букв, есть специальные символы:\n",
        "* **?а** - ноль или один символ **а**\n",
        "* **+а** - один или более символов **а**\n",
        "* **\\*а** - ноль или более символов **а** (не путать с +)\n",
        "* **.** - любое количество любого символа\n",
        "\n",
        "Пример:\n",
        "Выражению \\*a?b. соответствуют последовательности a, ab, abc, aa, aac НО НЕ abb!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7zOFFA3l_KQ"
      },
      "source": [
        "Рассмотрим подробно несколько наиболее полезных функций:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbJrUpARWhAd"
      },
      "source": [
        "### findall\n",
        "возвращает список всех найденных непересекающихся совпадений.\n",
        "\n",
        "Регулярное выражение **ab+c.**: \n",
        "* **a** - просто символ **a**\n",
        "* **b+** - один или более символов **b**\n",
        "* **c** - просто символ **c**\n",
        "* **.** - любой символ\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2athHzKuWhAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75dfa4df-acc7-4805-856c-c02a7b045584"
      },
      "source": [
        "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc') \n",
        "print(result)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abcd', 'abca']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9FpIw5RWhAf"
      },
      "source": [
        "Вопрос на внимательность: почему нет abcx?\n",
        "\n",
        "потому что пересекается"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5ttzoxEWhAg"
      },
      "source": [
        "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZR2AEq3WhAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282df29a-70e5-4568-f0fe-e080ce4dcb7b"
      },
      "source": [
        "# \\b - word-boundary, \\w - [A-Za-z0-9_]\n",
        "result = re.findall(r'\\b(\\w\\w?)', 'It is more than a university')\n",
        "print(result)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'mo', 'th', 'a', 'un']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI18l-l9WhAk"
      },
      "source": [
        "### split\n",
        "разделяет строку по заданному шаблону\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVKdRoc1WhAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1235f8aa-2ca7-4b5f-e4c9-b6fe0a685ec8"
      },
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie') \n",
        "print(result)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['itsy', ' bitsy', ' teenie', ' weenie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10u5efuSWhAm"
      },
      "source": [
        "можно указать максимальное количество разбиений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U9EQZMwWhAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89b5d998-36d3-4568-f2ff-b7ec29a5dc26"
      },
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit=2) \n",
        "print(result)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['itsy', ' bitsy', ' teenie, weenie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EMcMyflWhAp"
      },
      "source": [
        "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVgPSjEOWhAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e21f00b-0832-4b84-8d79-11239043b461"
      },
      "source": [
        "result = re.split('\\.[^\\b]', 'One. Two. Three. Four. Five.', maxsplit=2)\n",
        "print(result)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['One', 'Two', 'Three. Four. Five.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wrEGqBSWhAr"
      },
      "source": [
        "### sub\n",
        "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
        "\n",
        "параметры: (pattern, repl, string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az3KxKWwWhAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ad6a95-6d53-4f42-85f7-7acde728f036"
      },
      "source": [
        "result = re.sub('a', 'b', 'abcabc')\n",
        "print(result)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bbcbbc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD0n7_HPWhAt"
      },
      "source": [
        "**Задание**: напишите регулярное выражение, которое позволит заменить все цифры в строке на \"DIG\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Sdu7xlWhAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5cfd9b-b333-48dd-febc-9b45e291eb2c"
      },
      "source": [
        "# \\d - любая цифра\n",
        "result = re.sub('\\d+', 'DIG', '+7 (800) 555-35-35')\n",
        "print(result)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+DIG (DIG) DIG-DIG-DIG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8__oi1PWhAv"
      },
      "source": [
        "**Задание**: напишите  регулярное выражение, которое позволит убрать url из строки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwNS9zt4WhAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9607e932-86c8-430f-98ce-76e7fe2313a8"
      },
      "source": [
        "result = re.sub(r'(\\w*:\\/\\/)?(www.)?[\\w]+\\.\\w+(\\/[\\w]+\\/?)*\\b', '', 'It is more than itmo.ru or http://iTmo.ru or https://itmo.ru or even itmo.ru/home')\n",
        "print(result)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is more than  or  or  or even \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gStgBJy2WhAx"
      },
      "source": [
        "### compile\n",
        "компилирует регулярное выражение в отдельный объект"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JstTupisWhAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b20d6da-c57d-4085-93d8-1775a1fa7831"
      },
      "source": [
        "# Пример: построение списка всех слов строки:\n",
        "prog = re.compile('[А-Яа-яё\\-]+')\n",
        "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXEXc3G0WhA2"
      },
      "source": [
        "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFvnIWbUWhA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2365d489-37f4-407b-c22c-561d29650c94"
      },
      "source": [
        "rx = re.compile('[А-Яа-яё\\-|A-Za-z]{4,}')\n",
        "result = rx.findall('Слова? Да, больше, ещё больше слов! Что-то ещё. And English.')\n",
        "print(result)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Слова', 'больше', 'больше', 'слов', 'Что-то', 'English']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQDNZ3HQWhA3"
      },
      "source": [
        "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
        "\n",
        "```\n",
        "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ?<=@ - если следует после @ с определенными условями \n",
        "rx = re.compile(r'(?<=@)(\\w[\\w-]*\\w(?:\\.\\w[\\w-]*\\w)*)\\b')\n",
        "result = rx.findall('abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHHMy2CejQS5",
        "outputId": "efd883a6-20c9-4fb9-c8af-2c160897ee3e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gmail.com', 'test.in', 'analyticsvidhya.com', 'rest.biz']\n"
          ]
        }
      ]
    }
  ]
}